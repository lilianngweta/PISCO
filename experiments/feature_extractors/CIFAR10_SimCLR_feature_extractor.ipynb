{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import requred libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from numpy import save\n",
    "\n",
    "# for simclr\n",
    "from simclr_feature_extraction import get_features\n",
    "import argparse\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import get_resnet\n",
    "from pprint import pprint\n",
    "from utils import yaml_config_hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download CIFAR 10 data form torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10('~/datasets/cifar', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10('~/datasets/cifar', train=False, download=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_contrast(images_data, contrast_factor):\n",
    "    to_tensor = transforms.ToTensor()   \n",
    "    images_list = [to_tensor(im) for im in images_data]\n",
    "    images = torch.stack(images_list)\n",
    "    contrasted_images = F.adjust_contrast(images, contrast_factor)\n",
    "    contrasted_images = np.array(np.stack([transforms.ToPILImage()(im) for im in contrasted_images]))\n",
    "    return contrasted_images\n",
    "\n",
    "def apply_rotation(images_data, angle=30):\n",
    "    rotated_images = []\n",
    "    for img in images_data:\n",
    "        rotated_image = ndimage.rotate(img, angle, reshape=False)\n",
    "        rotated_images.append(rotated_image)\n",
    "    rotated_images = np.array(rotated_images)\n",
    "    return rotated_images\n",
    "\n",
    "def blur_images(images_data, sigma=1):\n",
    "    blurred_images = []\n",
    "    for img in images_data:\n",
    "        blurred_image = gaussian_filter(img, sigma)\n",
    "        blurred_images.append(blurred_image)\n",
    "    blurred_images = np.array(blurred_images)\n",
    "    return blurred_images\n",
    "\n",
    "\n",
    "def apply_saturation(images_data, sat_factor):\n",
    "    to_tensor = transforms.ToTensor()   \n",
    "    images_list = [to_tensor(im) for im in images_data]\n",
    "    images = torch.stack(images_list)\n",
    "    saturated_images = F.adjust_saturation(images, sat_factor)\n",
    "    saturated_images = np.array(np.stack([transforms.ToPILImage()(im) for im in saturated_images]))\n",
    "    return saturated_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform images and extract their features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Setting up the parameters from the parameters file config.yaml\n",
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook(\"./config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# args.device = torch.device(\"cpu\")\n",
    "\n",
    "# override some configuration parameters \n",
    "args.batch_size = 64\n",
    "# pprint(vars(args))\n",
    "\n",
    "# don't load a pre-trained model from PyTorch repo\n",
    "encoder = get_resnet(args.resnet, pretrained=False) \n",
    "\n",
    "# get dimensions of fc layer\n",
    "n_features = encoder.fc.in_features  \n",
    "\n",
    "# load pre-trained SimCLR model from checkpoint - pr-etrained on CIFAR10\n",
    "simclr_model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "model_fp = './saved_models/checkpoint_100_simclr_original.tar'\n",
    "\n",
    "simclr_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "simclr_model = simclr_model.to(args.device)\n",
    "simclr_model.eval()\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform images \n",
    "\n",
    "# Transformation parameters\n",
    "angle = 15 # for rotation\n",
    "contrast_factor = 0.3 # for contrast\n",
    "sigma = 0.5 # for blur\n",
    "saturation_factor = 5 # for saturation\n",
    "\n",
    "train_labels = np.array(train_dataset.targets)\n",
    "test_labels = np.array(test_dataset.targets)\n",
    "\n",
    "X_train_og = train_dataset.data\n",
    "X_train_rotated = apply_rotation(train_dataset.data, angle)\n",
    "X_train_contrasted = apply_contrast(train_dataset.data, contrast_factor) \n",
    "X_train_blurred = blur_images(train_dataset.data, sigma)\n",
    "X_train_saturated = apply_saturation(train_dataset.data, saturation_factor)\n",
    "\n",
    "\n",
    "X_test_og = test_dataset.data\n",
    "X_test_rotated = apply_rotation(test_dataset.data, angle)\n",
    "X_test_contrasted = apply_contrast(test_dataset.data, contrast_factor) \n",
    "X_test_blurred = blur_images(test_dataset.data, sigma)\n",
    "X_test_saturated = apply_saturation(test_dataset.data, saturation_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Extracting features using SimCLR model pre-trained on CIFAR10 ###\n",
      "h features shape (50000, 512)\n",
      "h features shape (50000, 512)\n",
      "h features shape (50000, 512)\n",
      "h features shape (50000, 512)\n",
      "h features shape (50000, 512)\n",
      "h features shape (10000, 512)\n",
      "h features shape (10000, 512)\n",
      "h features shape (10000, 512)\n",
      "h features shape (10000, 512)\n",
      "h features shape (10000, 512)\n"
     ]
    }
   ],
   "source": [
    "# Extract image features\n",
    "print(\"### Extracting features using SimCLR model pre-trained on CIFAR10 ###\")\n",
    "Z_train_og, _ = get_features(X_train_og, simclr_model, args.batch_size, args.device)\n",
    "Z_train_rotated, _ = get_features(X_train_rotated, simclr_model, args.batch_size, args.device)\n",
    "Z_train_contrasted, _= get_features(X_train_contrasted, simclr_model, args.batch_size, args.device)\n",
    "Z_train_blurred, _= get_features(X_train_blurred, simclr_model, args.batch_size, args.device)\n",
    "Z_train_saturated, _ = get_features(X_train_saturated, simclr_model, args.batch_size, args.device)\n",
    "\n",
    "\n",
    "Z_test_og, _ = get_features(X_test_og, simclr_model, args.batch_size, args.device)\n",
    "Z_test_rotated, _ = get_features(X_test_rotated, simclr_model, args.batch_size, args.device)\n",
    "Z_test_contrasted, _= get_features(X_test_contrasted, simclr_model, args.batch_size, args.device)\n",
    "Z_test_blurred, _= get_features(X_test_blurred, simclr_model, args.batch_size, args.device)\n",
    "Z_test_saturated, _ = get_features(X_test_saturated, simclr_model, args.batch_size, args.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save extracted features and image labels as numpy files\n",
    "\n",
    "save('../data/Z_train_og_cifar10_simclr.npy', Z_train_og)\n",
    "save('../data/Z_train_rotated_cifar10_simclr.npy', Z_train_rotated)\n",
    "save('../data/Z_train_contrasted_cifar10_simclr.npy', Z_train_contrasted)\n",
    "save('../data/Z_train_blurred_cifar10_simclr.npy', Z_train_blurred)\n",
    "save('../data/Z_train_saturated_cifar10_simclr.npy', Z_train_saturated)\n",
    "\n",
    "save('../data/Z_test_og_cifar10_simclr.npy', Z_test_og)\n",
    "save('../data/Z_test_rotated_cifar10_simclr.npy', Z_test_rotated)\n",
    "save('../data/Z_test_contrasted_cifar10_simclr.npy', Z_test_contrasted)\n",
    "save('../data/Z_test_blurred_cifar10_simclr.npy', Z_test_blurred)\n",
    "save('../data/Z_test_saturated_cifar10_simclr.npy', Z_test_saturated)\n",
    "\n",
    "save('../data/train_labels_cifar10.npy', train_labels)\n",
    "save('../data/test_labels_cifar10.npy', test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:invariance_env]",
   "language": "python",
   "name": "conda-env-invariance_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
